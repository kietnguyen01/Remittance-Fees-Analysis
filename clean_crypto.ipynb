{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import miceforest as mf\n",
    "import coingecko_api as ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_xrp_bsv(scraped: dict) -> dict:\n",
    "    \"\"\"Calculate average_transaction_fees for XRP/BSV dataframes. Merge API and Messari dataframes for those projects\"\"\"\n",
    "    # Merge XRP and BSV dataframes\n",
    "    for name in ['xrp', 'bsv']:\n",
    "        scraped[name] = scraped[f'{name}_bit'].join(scraped[f'{name}_mes'], on='date', how='inner')\n",
    "        # Calculate average_transaction_fees column\n",
    "        scraped[name] = scraped[name].with_columns((pl.col(\"total_fees\") / pl.col(\"transactions_count\")).alias(\"average_transaction_fees\"))\n",
    "        # Drop total_fees column\n",
    "        scraped[name] = scraped[name].drop('total_fees')\n",
    "    return scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_api_scraped(filled_api: dict, filled_scraped: dict, names: list) -> dict:\n",
    "    \"\"\"Merge API and scraped data into a single dictionary of dataframes\"\"\"\n",
    "    # Fill missing dates in Messari data with null values\n",
    "    for name in ['xrp_mes', 'bsv_mes', 'xlm']:\n",
    "        filled_scraped[name] = ca.fill_date(filled_scraped[name])\n",
    "\n",
    "    # Clean XRP and BSV dataframes\n",
    "    clean_xrp_bsv(filled_scraped)\n",
    "\n",
    "    # Merge API and scraped data\n",
    "    combined = {}\n",
    "    for name in names:\n",
    "        combined[name] = filled_api[name].join(filled_scraped[name], on='date', how='inner')\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mf_impute(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return imputed pandas dataframe using MICE\"\"\"\n",
    "    kernel = mf.ImputationKernel(\n",
    "        df,\n",
    "        datasets=3,\n",
    "        save_all_iterations=True,\n",
    "        random_state=123\n",
    "    )\n",
    "    # Run the MICE algorithm for 3 iterations on each of the datasets\n",
    "    kernel.mice(3)\n",
    "    return kernel.complete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_crypto(dfs: dict) -> dict:\n",
    "    \"\"\"Impute missing values in dataframes of a dict\"\"\"\n",
    "    # Convert Polars to pandas\n",
    "    pandas_dfs = {k: df.to_pandas() for k, df in dfs.items()}\n",
    "\n",
    "    # Impute each dataframe\n",
    "    imputed = {}\n",
    "    for k, df in pandas_dfs.items():\n",
    "        date_series = df['date']  # Get date column as a series\n",
    "        df_no_date = df.drop('date', axis=1)\n",
    "        df_imputed = mf_impute(df_no_date)\n",
    "        # Concatenate the date back to the imputed dataframe\n",
    "        imputed[k] = pd.concat([date_series, df_imputed], axis=1)\n",
    "\n",
    "    # Convert pandas to Polars\n",
    "    return {k: pl.from_pandas(df) for k, df in pandas_dfs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
