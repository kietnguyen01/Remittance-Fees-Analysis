{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from coingecko_api.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import miceforest as mf\n",
    "import coingecko_api as ca\n",
    "from scipy.stats.mstats import winsorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_df(df: pl.DataFrame, limits: tuple=(0.05, 0.05)) -> pl.DataFrame:\n",
    "    \"\"\"Winsorize Messari data to remove extreme outliers\"\"\"\n",
    "    # Loop through the columns except the first one\n",
    "    for col in df.columns[1:]:\n",
    "        # Apply winsorization with 5% of the lowest/highest replaced\n",
    "        col_values = df[col].to_numpy()\n",
    "        win_values = winsorize(col_values, limits=limits)\n",
    "        new_col = pl.Series(name=col, values=win_values)\n",
    "\n",
    "        # Replace the original column with the winsorized column\n",
    "        df = df.drop(col)\n",
    "        df = df.with_columns(**{col: new_col})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_xrp_bsv(scraped: dict) -> dict:\n",
    "    \"\"\"Calculate average_transaction_fees for XRP/BSV dataframes. Merge API and Messari dataframes for those projects\"\"\"\n",
    "    # Merge XRP and BSV dataframes\n",
    "    for name in ['xrp', 'bsv']:\n",
    "        scraped[name] = scraped[f'{name}_bit'].join(scraped[f'{name}_mes'], on='date', how='inner')\n",
    "        # Calculate average_transaction_fees column\n",
    "        scraped[name] = scraped[name].with_columns((pl.col(\"total_fees\") / pl.col(\"transactions_count\")).alias(\"average_transaction_fees\"))\n",
    "        # Drop total_fees column\n",
    "        scraped[name] = scraped[name].drop('total_fees')\n",
    "    return scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_api_scraped(api_data: dict, scraped_data: dict, names: list) -> dict:\n",
    "    \"\"\"Merge API and scraped data into a single dictionary of dataframes\"\"\"\n",
    "    # Clean scraped dataframes\n",
    "    for name in ['xrp_mes', 'bsv_mes', 'xlm']:\n",
    "        scraped_data[name] = winsorize_df(scraped_data[name])\n",
    "        scraped_data[name] = ca.fill_date(scraped_data[name])\n",
    "    combine_xrp_bsv(scraped_data)\n",
    "\n",
    "    # Merge API and scraped data\n",
    "    combined = {}\n",
    "    for name in names:\n",
    "        combined[name] = api_data[name].join(scraped_data[name], on='date', how='inner')\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mf_impute(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return imputed pandas dataframe using MICE\"\"\"\n",
    "    kernel = mf.ImputationKernel(\n",
    "        df,\n",
    "        datasets=3,\n",
    "        save_all_iterations=True,\n",
    "        random_state=123\n",
    "    )\n",
    "    # Run the MICE algorithm for 3 iterations on each of the datasets\n",
    "    kernel.mice(3)\n",
    "    return kernel.complete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_dfs(dfs: dict) -> dict:\n",
    "    \"\"\"Impute missing values in dataframes of a dict\"\"\"\n",
    "    # Convert Polars to pandas\n",
    "    pandas_dfs = {k: df.to_pandas() for k, df in dfs.items()}\n",
    "\n",
    "    # Impute each dataframe\n",
    "    imputed = {}\n",
    "    for k, df in pandas_dfs.items():\n",
    "        date_series = df['date']  # Get date column as a series\n",
    "        df_no_date = df.drop('date', axis=1)\n",
    "        df_imputed = mf_impute(df_no_date)\n",
    "\n",
    "        # Concatenate the date back to the imputed dataframe\n",
    "        imputed[k] = pd.concat([date_series, df_imputed], axis=1)\n",
    "\n",
    "    # Convert pandas to Polars\n",
    "    return {k: pl.from_pandas(df) for k, df in imputed.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
