{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xlsxwriter\n",
    "import polars as pl\n",
    "from datetime import date, timedelta\n",
    "from urllib.parse import unquote\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_source(url: str, driver: webdriver, start_date: str, end_date: str) -> str:\n",
    "    \"\"\"Scrape token data from BitInfoCharts with headless Selenium\"\"\"\n",
    "    # Wait for the chart to load and get page source\n",
    "    driver.get(url)\n",
    "    wait = WebDriverWait(driver, 1)\n",
    "    wait.until(EC.presence_of_element_located((By.ID, 'container')))\n",
    "    html = driver.page_source\n",
    "\n",
    "    # Find the intended start and end dates using regex\n",
    "    start = re.search(rf'\\[new Date\\(\"{start_date}\"\\)', html, re.DOTALL)\n",
    "    end = re.search(rf'\\[new Date\\(\"{end_date}\"\\)[^\\]]*', html, re.DOTALL)\n",
    "\n",
    "    # Use a try-except block to handle the case when end is None\n",
    "    try:\n",
    "        # Extract the graph data in between\n",
    "        graph_data = html[start.start():end.end() + 1]\n",
    "    except AttributeError:\n",
    "        # Use the last date found as the end index\n",
    "        end_str = re.findall(r'\\[new Date\\(\"[\\d/]*\"\\)[^\\]]*\\]', html, re.DOTALL)[-1]\n",
    "        end = re.search(end_str, html, re.DOTALL)\n",
    "        graph_data = html[start.start():end.end() + 1]\n",
    "\n",
    "    return graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_vals(stats: list, driver: webdriver, start: str, end: str) -> dict:\n",
    "    \"\"\"Extract stat values from scraped page source into polars dataframe\"\"\"\n",
    "    url_start = 'https://bitinfocharts.com/comparison/'\n",
    "    url_end = '.html#alltime'\n",
    "\n",
    "    # Dict with empty list for each stat key\n",
    "    token_dict = {stat: [] for stat in stats}\n",
    "\n",
    "    for stat in stats:\n",
    "        full_url = unquote(url_start + stat + url_end)  # Decode url with special chars\n",
    "        data = scrape_source(full_url, driver, start, end)\n",
    "\n",
    "        # Extract stat values from scraped data\n",
    "        pattern = r'new Date\\(\"(.+?)\"\\),([\\d.]+)'\n",
    "        matches = re.findall(pattern, data)\n",
    "        for match in matches:\n",
    "            token_dict[stat].append(float(match[1]))\n",
    "\n",
    "    return token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(token_dict: dict, start_date: date=date(2019, 1, 1), end_date: date=date(2022, 12, 31)) -> pl.DataFrame:\n",
    "    \"\"\"Create polars dataframe with date column and token data\"\"\"\n",
    "    # Create separate dataframe for each state, concat them and extend the shorter columns\n",
    "    df = pl.concat(\n",
    "        items=[pl.DataFrame({_name: _values})\n",
    "            for _name, _values in token_dict.items()],\n",
    "        how=\"horizontal\",\n",
    "    )\n",
    "\n",
    "    # Create polars dataframe with date column\n",
    "    delta = end_date - start_date\n",
    "    dates = [start_date + timedelta(days=i) for i in range(delta.days + 1)]\n",
    "    df = df.with_columns(pl.Series(\"date\", dates))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scrape_dict(token_stats: dict, driver: webdriver, start: str, end: str) -> dict:\n",
    "    \"\"\"Create a dictionary of Polars dataframes for each crypto id\"\"\"\n",
    "    # Build a dataframe for each token and its stats list\n",
    "    token_dfs = {}\n",
    "    for token, stats in token_stats.items():\n",
    "        token_dict = extract_vals(stats, driver, start, end)\n",
    "        token_df = create_dataframe(token_dict)\n",
    "        token_dfs[token] = token_df\n",
    "    return token_dfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
